{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Obtaining dependency information for opencv-python from https://files.pythonhosted.org/packages/32/a6/4321f0f30ee11d6d85f49251d417f4e885fe7638b5ac50b7e3c80cccf141/opencv_python-4.8.0.76-cp37-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading opencv_python-4.8.0.76-cp37-abi3-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/homebrew/anaconda3/envs/hands/lib/python3.11/site-packages (from opencv-python) (1.25.2)\n",
      "Downloading opencv_python-4.8.0.76-cp37-abi3-macosx_11_0_arm64.whl (33.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.8.0.76\n"
     ]
    }
   ],
   "source": [
    "#conda create --name hands python=3.11\n",
    "\n",
    "#!pip install mediapipe\n",
    "#!pip install ipywidgets\n",
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "# The MediaPipe Hand Landmarker task requires a trained model that is compatible with this task. \n",
    "#For more information on available trained models for Hand Landmarker, see the task overview Models section.\n",
    "\n",
    "# Select and download the model, and then store it in a local directory:\n",
    "\n",
    "# https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/index#models\n",
    "\n",
    "model_path = 'hand_landmarks.task'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # image\n",
    "\n",
    "# import mediapipe as mp\n",
    "\n",
    "# BaseOptions = mp.tasks.BaseOptions\n",
    "# HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "# HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "# VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "# # Create a hand landmarker instance with the image mode:\n",
    "# options = HandLandmarkerOptions(\n",
    "#     base_options=BaseOptions(model_asset_path='/path/to/model.task'),\n",
    "#     running_mode=VisionRunningMode.IMAGE)\n",
    "# with HandLandmarker.create_from_options(options) as landmarker:\n",
    "#   # The landmarker is initialized. Use it here.\n",
    "#   # ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video \n",
    "import mediapipe as mp\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "# Create a hand landmarker instance with the video mode:\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='/path/to/model.task'),\n",
    "    running_mode=VisionRunningMode.VIDEO)\n",
    "with HandLandmarker.create_from_options(options) as landmarker:\n",
    "  # The landmarker is initialized. Use it here.\n",
    "  # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89c2f47a41d4fab967b8796486a2ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m         cap\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m     34\u001b[0m \u001b[39m# Call the function to display the video stream\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m display_video_stream()\n",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m, in \u001b[0;36mdisplay_video_stream\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m         display(widgets\u001b[39m.\u001b[39mImage(value\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mimencode(\u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m, frame_rgb)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtobytes()))\n\u001b[0;32m---> 28\u001b[0m         time\u001b[39m.\u001b[39msleep(\u001b[39m0.1\u001b[39m)  \u001b[39m# Adjust the delay as needed\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     \u001b[39m# Release the capture object\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     cap\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Function to display video stream\n",
    "def display_video_stream():\n",
    "    # Open a video capture object (0 represents the default webcam)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # cap.set(3, 640)  # Width\n",
    "    # cap.set(4, 480)  # Height\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Convert the frame from BGR to RGB (OpenCV uses BGR by default)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Display the frame in the notebook\n",
    "            clear_output(wait=True)\n",
    "            display(widgets.Image(value=cv2.imencode('.jpg', frame_rgb)[1].tobytes()))\n",
    "            time.sleep(0.1)  # Adjust the delay as needed\n",
    "            \n",
    "    finally:\n",
    "        # Release the capture object\n",
    "        cap.release()\n",
    "\n",
    "# Call the function to display the video stream\n",
    "display_video_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hands",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
